%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%        REPORT OF THE PROJECT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,amsthm,amsopn}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{hyperref}
%\usepackage{tikz}
%\usepackage{array}
%\usepackage[top=1cm,bottom=1cm]{geometry}
%\usepackage{listings}
%\usepackage{xcolor}

% fancy headers and footers

%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\fancyhead[L]{BCPST 2 - Lycée Jacques Prévert}
%\fancyhead[R]{Rappels d'analyse}
%\pagenumbering{gobble} % no page numbering

% Création des labels Théorème, Lemme, etc...

\newtheoremstyle{break}%
{}{}%
{\itshape}{}%
{\bfseries}{}%  % Note that final punctuation is omitted.
{\newline}{}

\newtheoremstyle{sc}%
{}{}%
{}{}%
{\scshape}{}%  % Note that final punctuation is omitted.
{\newline}{}

\theoremstyle{break}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lm}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{sc}
\newtheorem{exo}{Exercice}

\theoremstyle{definition}
\newtheorem{defi}[thm]{Definition}
\newtheorem{ex}[thm]{Example}

\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}

% Raccourcis pour les opérateurs mathématiques (les espaces avant-après sont modifiés pour mieux rentrer dans les codes mathématiques usuels)
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\Img}{Im}
\DeclareMathOperator{\Card}{Card}
\DeclareMathOperator{\Vect}{Vect}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\Mod}{mod}


% Nouvelles commandes
\newcommand{\ps}[2]{\left\langle#1,#2\right\rangle}
\newcommand{\ent}[2]{[\![#1,#2]\!]}
\newcommand{\diff}{\mathop{}\!\mathrm{d}}
\newcommand{\ie}{\emph{i.e. }}

% opening
\title{Normal bases generation in C}
\author{Édouard \textsc{Rousseau}\\Supervised by Michaël \textsc{Quisquater}}



\begin{document}

\maketitle

\begin{abstract}
  This is the report of a C project about the generation of normal elements in
  finite fields. Consider a field extension $\mathbb{F}_{p^d}/\mathbb{F}_p$, we
  say that $\alpha\in\mathbb{F}_{p^d}$ is normal if $\left\{
  \alpha,\alpha^p,\alpha^{p^2},\cdots,\alpha^{p^{d-1}} \right\}$ is a basis of
  $\mathbb{F}_{p^d}$ over $\mathbb{F}_p$. We first give some theory to
  characterize normal elements, then we describe three algorithms to compute
  normal elements : a randomized algorithm, Lüneburg's algorithm, and
  Lenstra's algorithm. Finally, we give experimental results about our
  implementation. All this work is based on Gao's PhD thesis~\cite{Ga93}.

\end{abstract}

\tableofcontents

\clearpage

\section{Introduction}
\subsection{Normal bases}
With the rise of electronics and computer science, areas like
cryptography and coding theory have been largely studied. In both these
domains, finite fields often have a fundamental role. Normal bases can be
used to implement efficiently the finite fields arithmetic in the hardware,
consumming less power than other bases. But normal bases can also be used as a
theoretic tools to understand field extensions, and it is probably why normal bases were
studied since the $19^\textrm{th}$ century. Gauss, for example, used normal
bases to study when regular polygons can be drawn with ruler and compass
alone, a \emph{very} old problem. The notion of normal bases is not linked
with finite fields, if $\mathbb{K}$ is a field and $\mathbb{L}$ is a finite
Galois extension of $\mathbb{K}$ of Galois group $G$, a normal basis of
$\mathbb{L}$ over $\mathbb{K}$ is a basis of the form $\left\{
  \sigma(\alpha)\;|\;\sigma\in G
\right\}$ where $\alpha\in\mathbb{L}$. In other words, it is a basis composed
of an element $\alpha$ and all its conjugates. In the case of finite fields,
the definition that we give is indeed the same as this one, since, in this case,
$G$ is generated by the Frobenius automorphism. Given a finite Galois extension
$\mathbb{L}/\mathbb{K}$, normal bases can also be used to realize the Galois
correspondence of $\mathbb{L}/\mathbb{K}$. Theory tells us that there exists a
correspondence intermediate between extensions of $\mathbb{L}/\mathbb{K}$ and subgroups
of $G$, but it does not give an \emph{effective} way of realising that
correspondence. Normal bases are a way to solve that problem. In this report, we
focus on the problem of finding normal elements in finite fields. That is
why, from now on, we do not look at cases other then finite extensions
of finite fields (\ie extensions of type
$\mathbb{F}_{q^d}/\mathbb{F}_q$).
\subsection{Recalls and notations}
In all the text, we denote by $\mathbb{F}_n$ the field with $n$ elements. We
recall that $n$ must be a \emph{prime power} (\ie $n=p^d$ where $p$ is a prime
number and $d$ is a positive number). We have
$\mathbb{F}_{p^d}\cong\mathbb{F}_p[X]/(P)$, where $P$ is an irreducible
polynomial of degree $d$ in $\mathbb{F}_p[X]$, and this is the representation
that will be used in the C code. From now, we note
$X$ both for the indeterminate $X$ and for its image $\bar X$ in the
quotient $\mathbb{F}_p[X]/(P)$. $\mathbb{F}_{p^d}$ is a vector space over
$\mathbb{F}_p$, of dimension $d$, the basis $\left\{ 1, X, X^2, \dots, 
X^{d-1} \right\}$ is called the \emph{polynomial basis} in the following. We also recall
that $\mathbb{F}_{p^d}$ is a \emph{field extension} of $\mathbb{F}_p$ and the
characteristic of $\mathbb{F}_{p^d}$ is $p$. Lastly, we denote by $\sigma$ the
\emph{Frobenius map}, defined by $\sigma(x)=x^p$ for all
$x\in\mathbb{F}_{p^d}$. This map is a $\mathbb{F}_p$-automorphism of
$\mathbb{F}_{p^d}$ (\ie $\sigma$ is a field morphism, a bijection, and $\forall
y\in\mathbb{F}_p,\;\sigma(y)=y$), as a consequence, $\sigma$ is also a linear
map.

Note that we look only
at \emph{prime extensions}, (\ie extensions of type
$\mathbb{F}_{p^d}/\mathbb{F}_p$). This choice has been made because the theory
of normal elements in extensions of type $\mathbb{F}_{q^n}/\mathbb{F}_q$ is not
different (replacing $p$ by $q$ in the following demontrations would be
sufficient), but the implementation of the algorithms is simpler in the case of
prime extensions. Speaking about implementation, we must introduce Flint
(Fast Library for Number Theory), because \emph{every} function wrote in this
project uses Flint.

\subsection{Flint}

Flint~\cite{Ha10} is a C library maintained by William Hart, and developed
by him and many others since 2007. In Flint, we use the type
\texttt{fq\_t}, where the elements of $F_{p^d}\cong\mathbb{F}_p[X]/(P)$ are
represented as polynomials of degree less than $d$. The underlying data
structure is \texttt{fmpz\_poly\_t}, that is a \texttt{struct} containing
\begin{enumerate}
  \item a pointer to arbitrary large integers \texttt{fmpz}, representing the
    coefficients of the polynomial;
  \item the number of memory allocations for the pointer of type
    \texttt{slong}: Flint's own \texttt{unsigned long};
  \item the degree of the polynomial, a \texttt{slong} too.
\end{enumerate}
In Flint, it is possible to work with finite fields of arbitrary large
order and with polynomials or matrices over these fields. The basic functions
are already implemented, such as gcd or derivative for polynomials, or reduced
row echelon form for matrices. Using Flint save a lot of time, but it also has
its limits. It is possible to deal with arbitrary \emph{prime}
extensions. For extension of type $\mathbb{F}_{q^n}/\mathbb{F}_q$, it is still
possible, using polynomial arithmetic over $\mathbb{F}_q$. But using
polynomials
over $\mathbb{F}_{q^n}$ would have required polynomial in two
indeterminates, and everything would be more complicated. That is the reason we
look only at prime extensions.

All these recalls being made, and the true hero
(Flint) of our functions being introduced, we can begin our journey.

\section{Basics on normal bases}

In all this section, we set $p$ a prime number and $d$ a positive number. We
work with the extension $\mathbb{F}_{p^d}/\mathbb{F}_p$ and the Frobenius
morphism $\sigma$ defined above. We are now able to give a formal definition
of a normal element and a normal basis.

\begin{defi}[normal element, normal basis]
  Let $\alpha\in\mathbb{F}_{p^d}$, we say that $\alpha$ is a \emph{normal
  element} if $\left\{ \alpha, \sigma(\alpha),\dots,\sigma^{d-1}(\alpha)
  \right\}=\left\{ \alpha, \alpha^{p}, \dots, \alpha^{p^{d-1}} \right\}$ is a
  basis of $\mathbb{F}_{p^d}$. Such a basis is called a \emph{normal basis}. 
\end{defi}

In order to recognize a normal element $\alpha$, we can compute the dimension of the
linear span of $\left\{ \sigma^i(\alpha) \;|\; 0\leq i < k \right\}$. A way of
doing that is to construct the matrix $M$ which columns are the coordinates of the
elements $\sigma^i(\alpha)$ in the polynomial basis, and to check if $M$ is
non-singular. This can be done using Gauss algorithm. This method is not
efficient so we work on other characterizations of normal elements. We need
two more definitions to be able to state our results.

\begin{defi}[trace function]
  The \emph{trace function}
  $\Tr_{p^d|p}:\mathbb{F}_{p^d}\to\mathbb{F}_p$ of the extension
$\mathbb{F}_{p^d}/\mathbb{F}_p$ is the function defined by
\[
  \Tr_{p^d|p}(\alpha) = \sum_{i=0}^{d-1}\alpha^{p^i}.
\]
It takes its values in $\mathbb{F}_p$ since $(\Tr_{p^d|p}(\alpha))^p
= \Tr_{p^d|p}(\alpha)$. 
\end{defi}

The trace is a tool that permit to know when a family of elements $\alpha_1,
\dots, \alpha_d$ forms a basis of $\mathbb{F}_{p^d}$ over
$\mathbb{F}_p$, using the discrinant of these elements.

\begin{defi}[discriminant]
  Let $\alpha_1, \dots, \alpha_d$ be elements in $\mathbb{F}_{p^d}$, the
  \emph{discriminant} $\Delta(\alpha_1, \dots, \alpha_d)$ of these elements
  is the determinant
  \[
    \Delta(\alpha_1, \dots, \alpha_d)=\det
    \begin{pmatrix}
      \Tr(\alpha_1\alpha_1) & \Tr(\alpha_1\alpha_2) & \dots &
      \Tr(\alpha_1\alpha_d) \\
      \Tr(\alpha_2\alpha_1) & \Tr(\alpha_2\alpha_2) & \dots &
      \Tr(\alpha_2\alpha_d) \\
      \vdots & \vdots & & \vdots \\
      \Tr(\alpha_d\alpha_1) & \Tr(\alpha_d\alpha_2) & \dots &
      \Tr(\alpha_d\alpha_d)
    \end{pmatrix}
  \]
  where $\Tr$ is the same trace as before. We ommit the indices because
  the extension is always the same.
\end{defi}

With this last tool, we can state our first theorem.

\begin{thm}[Theorem 2.2.1, \cite{Ga93}]
  For any $n$ elements $\alpha_1, \dots, \alpha_d$ in
  $\mathbb{F}_{p^d}$, they form a basis of $\mathbb{F}_{p^d}$ over
  $\mathbb{F}_p$ if and only if $\Delta(\alpha_1, \dots,
  \alpha_d)\neq0$.
\end{thm}

\begin{proof}
  First assume that $\alpha_1, \dots, \alpha_d$ form a basis of
  $\mathbb{F}_{p^d}$ over $\mathbb{F}_p$. We prove that
  $\Delta(\alpha_1, \dots, \alpha_d)\neq0$ by showing that the row vectors
  $L_1, \dots, L_d$ of
  the matrix in the definition of $\Delta(\alpha_1, \dots, \alpha_d)$ are
  linearly independent over $\mathbb{F}_p$, and thus the matrix is
  nonsingular. Suppose that there exists $c_1, \dots,
  c_d\in\mathbb{F}_p$ with $\sum_i c_iL_i = 0$, it means
  \[
    c_1\Tr(\alpha_1\alpha_j) + \dots + c_n\Tr(\alpha_d\alpha_j) =
    0\textrm{ for }1\leq j\leq d.
  \]
  Then with $\beta=c_1\alpha_1 + \dots + c_d\alpha_d$, by linearity of the
  trace function, we get $\Tr(\beta\alpha_j) = 0$ for $1\leq j\leq d$. Since
  $\alpha_1, \dots, \alpha_d$ is a basis of $\mathbb{F}_{p^d}$, it follows
  that $\Tr(\beta\alpha) = 0$ for all $\alpha\in\mathbb{F}_{p^d}$. If
  $\beta\neq0$, it means that $\Tr(\gamma)=0$ for all
  $\gamma\in\mathbb{F}_{p^d}$ : we can see that this is impossible by thinking
  of $\Tr(\gamma)$ as the trace of the multiplication-by-$\gamma$ linear map. So we have $\beta=0$, and then
  $c_1\alpha_1 + \dots + c_d\alpha_d = 0$ implies $c_1=\dots=c_d=0$.

  Conversely, assume that $\Delta(\alpha_1, \dots, \alpha_d)\neq0$ and
  $c_1\alpha_1+\dots+c_d\alpha_d=0$ for some $c_1, \dots,
  c_d\in\mathbb{F}_p$. By multiplying by $\alpha_j$, we have
  \[
    c_1\alpha_1\alpha_j+\dots+c_d\alpha_d\alpha_j\textrm{ for }1\leq j \leq d,
  \]
  and by applying the trace function, we get
  \[
    c_1\Tr(\alpha_1\alpha_j)+\dots+c_n\Tr(\alpha_d\alpha_j)\textrm{ for }1\leq
    j\leq d.
  \]
  But this is the same as $\sum c_iL_i=0$ where the $L_i$ are the rows of the
  matrix in $\Delta(\alpha_1, \dots, \alpha_d)$. Since this matrix is
  nonsingular by hypothesis, its rows are linearly independent and it follow
  that $c_1=\dots=c_d$. Therefore $\alpha_1, \dots, \alpha_d$ are linearly
  independant over $\mathbb{F}_p$, and form a family of $d$ vectors in a
  $d$-dimensionnal vector space, so $\alpha_1, \dots, \alpha_d$ form  basis of
  $\mathbb{F}_{p^d}$ over $\mathbb{F}_p$.
\end{proof}

This characterization is interesting in itself, but the matrix defined in
$\Delta(\alpha_1, \dots, \alpha_d)$ is quite complicated. Fortunately,
we can use a much simpler matrix.

\begin{cor}
  \label{circulantCor}
 The elements $\alpha_1, \dots, \alpha_d$ form a basis of
 $\mathbb{F}_{p^d}$ over $\mathbb{F}_p$ if and only if the matrix $A$ is
 nonsigular, where
 \[
   A = 
   \begin{pmatrix}
     \alpha_1 & \alpha_2 & \dots & \alpha_d \\
     \alpha_1^p & \alpha_2^p & \dots & \alpha_d^p \\
     \vdots & \vdots & & \vdots \\
     \alpha_1^{p^{d-1}} & \alpha_2^{p^{d-1}} & \dots &
     \alpha_d^{p^{d-1}}.
   \end{pmatrix}
 \]
\end{cor}
\begin{proof}
  We have $\Delta(\alpha_1, \dots, \alpha_d)=\det(A^tA)=(\det A)^2$.   
\end{proof}

We now have a simpler matrix to study, but it is still a matrix, so the nature
of the problem is the same as before. Next lemma allow us to change the nature
of the problem, by working with polynomials.

\begin{lm}
  \label{henselLm}
  For any $n$ elements $a_0, a_1, \dots, a_{d-1}\in\mathbb{F}_{p^d}$, the
  $d\times d$ circulant matrix
  \[
    c[a_0, a_1, \dots, a_{d-1}] =
    \begin{pmatrix}
      a_0 & a_1 & a_2 & \dots & a_{d-1} \\
      a_{d-1} & a_0 & a_1 & \dots & a_{d-2} \\
      a_{d-2} & a_{d-1} & a_0 & \dots & a_{d-3} \\
      \vdots & \vdots & \vdots & & \vdots \\
      a_1 & a_2 & a_3 & \dots & a_0
    \end{pmatrix}
  \]
  is nonsigular if and only if the polynomial $\sum a_iX^i$ is relatively
  prime to $X^d-1$.
\end{lm}
\begin{proof}
  Let $A$ be the following $d\times d$ permutation matrix 
  \[
    \begin{pmatrix}
      0 & 1 & 0 & \dots & 0 & 0 \\
      0 & 0 & 1 & \dots & 0 & 0 \\
      \vdots & \vdots & \vdots & & \vdots & \vdots \\
      0 & 0 & 0 & \dots & 0 & 1 \\
      1 & 0 & 0 & \dots & 0 & 0
    \end{pmatrix}.
  \]
  Then we see that $c[a_0, a_1, \dots, a_{d-1}] =
  \sum_{i=0}^{d-1}a_iA^i=f(A)$, where $f(X)=\sum_{i=0}^{d-1}a_iX^i$. On the
  first line of $A^i$, there is only one nonzero value, it is a $1$ in
  position $i+1$. Hence the matrices $A^0, A, \dots, A^{d-1}$, are linearly
  independant, and since $A^d=I_d$, we know that the minimal polynomial
  of $A$ is $X^d-1$. Assume that $f(X)$ is relatively prime to $X^d-1$. Then
  there are polynomials $a(X), b(X)$ such that
  \[ 
  a(X)f(X) + b(X)(X^d-1)=1,
\]
and so
\[
  a(A)f(A) = I_d,
\]
as $A^d-I_d=0$. This implies that $f(A)$ is invertible and so
nonsigular. Now assume that $f(X)$ and $X^d-1$ are not relatively prime, and
note $d(X)\neq1$ their gcd. Let $f(X)=f_1(X)d(X)$ and $X^d-1=h(X)d(X)$.
Since $\deg h < n$, we have $h(A)\neq0$. But $h(A)d(A)=0$, so we see that
$d(A)$ is singular. Therefore $f(A)=f_1(A)d(A)$ is also singular. We have shown
that $f(A)$ is singular if and only if $f(X)$ is relatively prime to $X^d-1$.
\end{proof}

We are now able to state the last result oh this section.

\begin{thm}[Hensel, 1888]
  \label{hensel}
  Let $\alpha\in\mathbb{F}_{p^d}$, $\alpha$ is a normal element of the
  extension $\mathbb{F}_{p^d}/\mathbb{F}_p$ if and only if the polynomial
  $\alpha^{p^{d-1}}X^{d-1}+\dots+\alpha^pX+\alpha\in\mathbb{F}_{p^d}[X]$ 
  is relatively prime to $X^d-1$.
\end{thm}
\begin{proof}
  $\alpha$ is a normal element, if, by definition, the elements $\alpha,
  \alpha^p, \dots, \alpha^{p^{d-1}}$ form a basis of
  $\mathbb{F}_{p^d}$ over $\mathbb{F}_p$. By
  Corollary~\ref{circulantCor}, this is
  true if and only if the matrix
  \[
    A =
    \begin{pmatrix}
      \alpha & \alpha^p & \alpha^{p^2} & \dots & \alpha^{p^{d-1}} \\
      \alpha^p & \alpha^{p^2} & \alpha^{p^3} & \dots & \alpha \\
      \vdots & \vdots & \vdots & & \vdots \\
      \alpha^{p^{d-1}} & \alpha & \alpha^p & \dots & \alpha^{p^{d-2}}
    \end{pmatrix}
  \]
  is nonsingular. But, reversing the order of the rows in $A$, from the second
  row to the last, we get the matrix $c[\alpha, \alpha^p, \dots,
  \alpha^{p^{d-1}}]$, that is nonsingular if and only if $A$ if
  nonsingular. By Lemma~\ref{henselLm}, $c[\alpha, \alpha^p, \dots,
  \alpha^{d-1}]$ is nonsingular if and only if $X^d-1$ and
  $\alpha^{p^{d-1}}X^{d-1}+\dots+\alpha^pX+\alpha$ are relatively prime.
  This proves the theorem.
\end{proof}
We now have a new characterization of normal elements. We can decide if an
element is normal or not by computing a gcd. It is more efficient that the
naive matrix method because we have efficient algorithms to compute the gcd.
The function \texttt{is\_normal} is exactly the implementation of this
method. The code of this function, and of all the others, is available at
\url{github.com/edouardRousseau/normalBases}.

\section{Computation of normal bases}
Before trying to compute normal elements, a natural question is to wander if
normal elements always exist in extensions of type
$\mathbb{F}_{p^{d}}/\mathbb{F}_p$. We do not prove this result here (it is done
in~\cite{Ga93}), but the answer is yes. Now that this natural fear has been
eliminated, we give some ways to compute normal elements. We use the same
notations as in the previous section.

\subsection{Randomized algorithm}
First, we give a randomized algorithm. Such algorithms are often based on the
same strategy.
\begin{enumerate}
  \item Take a random element, following a certain protocol.
  \item Check if this element verify the wanted property.
\end{enumerate}
Our algorithm also uses this strategy, that is why our first function
\texttt{is\_normal} is very important. But the protocol is also essential.
For example, if we just take an element completly at random in
$\mathbb{F}_{p^d}$, our algorithm will not be very efficient. The following
theorem helps us defining a better protocol.
\begin{thm}
  Let $f(X)$ be an irreducible polynomial of degree $d$ over
  $\mathbb{F}_p$ and $\alpha$ a root of $f(X)$. Let
  \[
    g(X)=\cfrac{f(X)}{(X-\alpha)f'(X)}.
  \]
  Then there are at least $p -d(d-1)$ elements $u$ in $\mathbb{F}_p$ such that
  $g(u)$ is a normal element of $\mathbb{F}_{p^d}$ over $\mathbb{F}_p$.
\end{thm}
\begin{proof}
  Let $\sigma_i=\sigma^i$ be the automorphism
  $\theta\to\theta^{p^i},\theta\in\mathbb{F}_{p^d}$, for $0\leq i <d$. Then
  $\alpha_i=\sigma_i(\alpha)$ is also a root of $f(X)$, for $0\leq i <d$. The
  automorphism $\sigma_i:\mathbb{F}_{p^d}\to\mathbb{F}_{p^d}$ can be extended
  into a ring morphism
  $\sigma_i:\mathbb{F}_{p^d}[X]\to\mathbb{F}_{p^d}[X]$ by setting
  $\sigma_i(X)=X$. We get
  \[
    g_i(X):=\sigma_i(g(X)) = \cfrac{f(X)}{(X-\alpha_i)f'(\alpha_i)},
  \]
  and we note that $\sigma_i\sigma_i(g(X)) = \sigma_{i+j}(g(X))$. Then
  $g_i(X)$ is a polynomial in $\mathbb{F}_{p^d}[X]$ having $\alpha_k$ as a root
  for $k\neq i$ and $g_i(\alpha_i)=1$. Hence, for $i\neq k$, we have that every
  root of $f(X)$ is also a root of $g_i(X)g_k(X)$, so
  \begin{equation}
    g_i(X)g_k(X) \equiv 0 \;(\Mod f(X)), \textrm{ for }i\neq k.
    \label{3.1}
  \end{equation}
  Note that 
  \begin{equation}
    g_1(X)+g_2(X)+\dots+g_d(X)-1=0,
    \label{3.2}
  \end{equation}
  since the left side is a polynomial of degree at most $d-1$ (all the
  $g_i$
  are of degree $d-1$) and has $\alpha_0,
  \alpha_1, \dots, \alpha_{d-1}$ as roots. Multiplying (\ref{3.2}) by $g_i(X)$
  and using (\ref{3.1}) to simplify, we have
  \begin{equation}
    g_i(X)^2 \equiv g_i(X)\;(\Mod f(x)).
    \label{3.3}
  \end{equation}
  We next set the matrix
  \[
    D=(\sigma_{i+j}(g(X)))_{0\leq i,j <0}
  \]
  and we study its determinant, $\Delta(X)$. From the equations
  (\ref{3.1}), (\ref{3.2}) and (\ref{3.3}), we wee that the entries of $D^tD$
  molulo $f(X)$ are all $0$, except on the main diagonal where they are all
  $1$. It follows that
  \[
    \Delta(X)^2 = \det(D^tD) \equiv 1\;(\Mod f(x)).
  \]
  This proves that $\Delta(X)$ is a nonzero polynomial of degree at most
  $d(d-1)$, since it is a sum of $d$ products of polynomials of degree
  $d-1$. Therefore $\Delta(X)$ has at most $d(d-1)$ roots in
  $\mathbb{F}_p$. The result follows from Corollary~\ref{circulantCor}, since the matrix
  $D(u)$ is exactly the one defined in the corollary applied to the elements
  $g(u), \sigma(g(u)),\dots,\sigma^{d-1}(g(u))$.
\end{proof}

\section{Experimental results}

\clearpage
\bibliographystyle{unsrt}
\bibliography{biblio}
\end{document}
